{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963f940c-27c9-482a-9e21-4b8eda49fd2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae23f6d-df08-41fb-8cd6-527cfc669759",
   "metadata": {},
   "source": [
    "Weather columns do not seem to have very strong predictive powers. We will omit those and furthermore explore modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b8716be-fcc9-49c2-b8e1-e887b8d82847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "import re\n",
    "import boto3\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import s3fs\n",
    "from math import pi\n",
    "from itertools import chain\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast, StructType\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, split, slice, count, when, expr, isnan, isnull, min, max, avg, sin, log10, cos \n",
    "from pyspark.sql.functions import date_format, to_timestamp, concat, unix_timestamp, substring, lit\n",
    "from pyspark.sql.functions import col, month, quarter, dayofweek,dayofmonth, year, dayofyear\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType,IntegerType\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "#model\n",
    "from pyspark.ml.regression import RandomForestRegressor, LinearRegression, LinearRegressionModel, RandomForestRegressionModel\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark_dist_explore import hist\n",
    "\n",
    "import configparser\n",
    "import findspark\n",
    "import lxml\n",
    "from datetime import timedelta\n",
    "from pandas.tseries.offsets import BDay\n",
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a179a3-5bd2-4807-96fe-f6c45d42c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:==========================================>              (9 + 3) / 12]\r"
     ]
    }
   ],
   "source": [
    "### Starting Pyspark Session\n",
    "\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "                    .config('spark.master','local[*]')\\\n",
    "                    .config('spark.add.name','S3app')\\\n",
    "                    .config('spark.jars.packages','org.apache.hadoop:hadoop-aws:3.3.4,org.apache.hadoop:hadoop-common:3.3.4')\\\n",
    "                    .config(\"spark.driver.memory\", \"20g\") \\\n",
    "                    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0738a03f-013f-4ffb-a4ae-5f1652683ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 01:50:55 WARN DAGScheduler: Broadcasting large task binary with size 1185.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Configuring Pyspark to read data from S3 Bucket. \n",
    "\n",
    "findspark.init()\n",
    "config = configparser.ConfigParser()\n",
    "# AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "# AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "aws_profile = 'default'\n",
    "config.read(os.path.expanduser(\"~/.aws/credentials\"))\n",
    "access_id = config.get(aws_profile, \"aws_access_key_id\") \n",
    "access_key = config.get(aws_profile, \"aws_secret_access_key\")\n",
    "# spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "# spark.conf.set(\"spark.network.io.preferDirectBufs\", \"false\")\n",
    "\n",
    "# spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "# spark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\", \"true\")\n",
    "\n",
    "sc=spark.sparkContext\n",
    "hadoop_conf=sc._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.committer.name\",\"magic\")\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"fs.s3a.awsAccessKeyId\", access_id)\n",
    "hadoop_conf.set(\"fs.s3a.awsSecretAccessKey\", access_key)\n",
    "# hadoop_conf.set('spark.sql.files.maxPartitionBytes','134217728')\n",
    "# hadoop_conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "# hadoop_conf.set(\"spark.sql.autoBroadcastJoinThreshold\", '104857600')\n",
    "# hadoop_conf.set(\"spark.sql.autoBroadcastJoinThreshold\", '-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2a391-2a66-41b7-b5ce-8b685e8b7a1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling with the base Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210f0cd-b5f7-4b29-811c-6d4877e8b504",
   "metadata": {},
   "source": [
    "No weather data, no holiday data, no events data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11daa16a-becd-4821-9890-7fdc0c430e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"s3a://w210-bucket/data_wrangling/final_df_prior_hr.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cb1bbb9-9ebf-4c67-a58d-21c221721577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redacted = df.drop('event_origin','event_dest','wind_speed_origin','air_temp_origin','precipitation_origin','wth_type_origin',\n",
    "                      'wind_speed_dest','air_temp_dest','precipitation_dest','precipitation_dest','wth_type_dest','number_of_searches','holiday_period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ad67020-602b-429f-a1e2-c01b2c576d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# casting certain columns to integer\n",
    "df_redacted = df_redacted.withColumn('day_of_month', dayofmonth(df_redacted.date)) \\\n",
    "       .withColumn('day_of_year', dayofyear(df_redacted.date)) \n",
    "df_redacted= df_redacted.withColumn(\"year\",col(\"year\").cast('integer'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1725ac2c-9e07-4b0a-8856-661a3461cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redacted = df_redacted.withColumn('average_route_crowd',f.when(f.col(\"average_route_crowd\").isNull(),f.lit(0)).otherwise(df_redacted.average_route_crowd))\n",
    "df_redacted = df_redacted.withColumn('prior_hr_route_crowd',f.when(f.col(\"prior_hr_route_crowd\").isNull(),f.lit(0)).otherwise(df_redacted.prior_hr_route_crowd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64ea2a08-b7db-471e-9011-ed34e23cf1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ridership_number: integer (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- quarter: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      " |-- origin-des: string (nullable = true)\n",
      " |-- average_route_crowd: double (nullable = true)\n",
      " |-- prior_hr_route_crowd: double (nullable = true)\n",
      " |-- day_of_month: integer (nullable = true)\n",
      " |-- day_of_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_redacted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d029ff88-f214-44eb-b427-1b08c6c6ecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "columns_categorical = ['hour','day_of_week','month','day_of_month','quarter','day_of_year','origin','destination']\n",
    "\n",
    "#Note:  day_of_year, day_of_month, and year should all be numeric?  lets just drop day_of_month and day_of_year for simple model?  not needed?\n",
    "\n",
    "columns_continues = ['year','average_route_crowd','prior_hr_route_crowd']\n",
    "\n",
    "print(\"phase1\")\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"hour\", outputCol=\"hour_index\")\n",
    "df_final_indexer = indexer.fit(df_redacted)\n",
    "df_final_indexer.write().overwrite().save(\"1indexer.save\")\n",
    "df_final = df_final_indexer.transform(df_redacted) \n",
    "ohe = OneHotEncoder(inputCol=\"hour_index\", outputCol=\"hour_index_ohe\")\n",
    "ohe_fit = ohe.fit(df_final)\n",
    "ohe_fit.write().overwrite().save(\"1ohe.save\")\n",
    "df_final = ohe_fit.transform(df_final)\n",
    "\n",
    "print(\"phase2\")\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"day_of_week\", outputCol=\"day_of_week_index\")\n",
    "df_final_indexer2 = indexer.fit(df_final)\n",
    "df_final_indexer2.write().overwrite().save(\"2indexer.save\")\n",
    "df_final = df_final_indexer2.transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"day_of_week_index\", outputCol=\"day_of_week_index_ohe\")\n",
    "ohe_fit2 = ohe.fit(df_final)\n",
    "ohe_fit2.write().overwrite().save(\"2ohe.save\")\n",
    "df_final = ohe_fit2.transform(df_final)\n",
    "\n",
    "print(\"phase3\")\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"month\", outputCol=\"month_index\")\n",
    "df_final_indexer3 = indexer.fit(df_final)\n",
    "df_final_indexer3.write().overwrite().save(\"3indexer.save\")\n",
    "df_final = df_final_indexer3.transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"month_index\", outputCol=\"month_index_ohe\")\n",
    "ohe_fit3 = ohe.fit(df_final)\n",
    "ohe_fit3.write().overwrite().save(\"3ohe.save\")\n",
    "df_final = ohe_fit3.transform(df_final)\n",
    "\n",
    "print(\"phase4\")\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"day_of_month\", outputCol=\"day_of_month_index\")\n",
    "df_final_indexer4 = indexer.fit(df_final)\n",
    "df_final_indexer4.write().overwrite().save(\"4indexer.save\")\n",
    "df_final = df_final_indexer4.transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"day_of_month_index\", outputCol=\"day_of_month_index_ohe\")\n",
    "ohe_fit4 = ohe.fit(df_final)\n",
    "ohe_fit4.write().overwrite().save(\"4ohe.save\")\n",
    "df_final = ohe_fit4.transform(df_final)\n",
    "\n",
    "print(\"phase5\")\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"quarter\", outputCol=\"quarter_index\")\n",
    "df_final_indexer5 = indexer.fit(df_final)\n",
    "df_final_indexer5.write().overwrite().save(\"5indexer.save\")\n",
    "df_final = df_final_indexer5.transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"quarter_index\", outputCol=\"quarter_index_ohe\")\n",
    "ohe_fit5 = ohe.fit(df_final)\n",
    "ohe_fit5.write().overwrite().save(\"5ohe.save\")\n",
    "df_final = ohe_fit5.transform(df_final)\n",
    "\n",
    "print(\"phase6\")\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"day_of_year\", outputCol=\"day_of_year_index\")\n",
    "df_final_indexer6 = indexer.fit(df_final)\n",
    "df_final_indexer6.write().overwrite().save(\"6indexer.save\")\n",
    "df_final = df_final_indexer6.transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"day_of_year_index\", outputCol=\"day_of_year_index_ohe\")\n",
    "ohe_fit6 = ohe.fit(df_final)\n",
    "ohe_fit6.write().overwrite().save(\"6ohe.save\")\n",
    "df_final = ohe_fit6.transform(df_final)\n",
    "\n",
    "print(\"phase7\")\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"origin\", outputCol=\"origin_index\")\n",
    "df_final_indexer7 = indexer.fit(df_final)\n",
    "df_final_indexer7.write().overwrite().save(\"7indexer.save\")\n",
    "df_final = df_final_indexer7.transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"origin_index\", outputCol=\"origin_index_ohe\")\n",
    "ohe_fit7 = ohe.fit(df_final)\n",
    "ohe_fit7.write().overwrite().save(\"7ohe.save\")\n",
    "df_final = ohe_fit7.transform(df_final)\n",
    "\n",
    "print(\"phase8\")\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"destination\", outputCol=\"destination_index\")\n",
    "df_final_indexer8 = indexer.fit(df_final)\n",
    "df_final_indexer8.write().overwrite().save(\"8indexer.save\")\n",
    "df_final = df_final_indexer8.transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"destination_index\", outputCol=\"destination_index_ohe\")\n",
    "ohe_fit8 = ohe.fit(df_final)\n",
    "ohe_fit8.write().overwrite().save(\"8ohe.save\")\n",
    "df_final = ohe_fit8.transform(df_final)\n",
    "\n",
    "assembler_categ = VectorAssembler(inputCols= ['hour_index_ohe','day_of_week_index_ohe','month_index_ohe',\n",
    "                                              'day_of_month_index_ohe','quarter_index_ohe','day_of_year_index_ohe',\n",
    "                                              'origin_index_ohe','destination_index_ohe'],\n",
    "                           outputCol=\"cat_features\")\n",
    "\n",
    "\n",
    "# vectoring continues variables\n",
    "assembler_cont = VectorAssembler(inputCols=columns_continues,\n",
    "                                   outputCol=\"cont_features\")\n",
    "\n",
    "df_final = assembler_categ.transform(df_final)\n",
    "df_final = assembler_cont.transform(df_final)\n",
    "assembler = VectorAssembler(inputCols= [\"cont_features\",\"cat_features\"],\n",
    "                               outputCol=\"features\")\n",
    "\n",
    "df_final = assembler.transform(df_final)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db9fd56c-0e93-461e-999c-386e49bd9f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#df_final_1 = df_final.filter(col('year') != 2011)\n",
    "df_final_1 = df_final.filter(col('year') > 2020)\n",
    "processed_train_df = df_final_1.filter(col('year') != 2022).select('ridership_number','features')\n",
    "processed_test_df =  df_final_1.filter(col('year') == 2022).select('ridership_number','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4dd64a6-078a-4240-aad0-98b3f1f6f855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# # saving as parquet in S3 bucket\n",
    "processed_train_df.write.parquet('s3a://w210-bucket/data_wrangling/murray_processed_df_train_redacted.parquet',mode='overwrite')\n",
    "processed_test_df.write.parquet('s3a://w210-bucket/data_wrangling/murray_processed_df_test_redacted.parquet',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2169b20-9055-41ac-9d35-459d3ae9f543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 296:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:27:26 WARN MemoryStore: Not enough space to cache rdd_581_2 in memory! (computed 1288.7 MiB so far)\n",
      "23/04/11 04:27:26 WARN BlockManager: Persisting block rdd_581_2 to disk instead.\n",
      "23/04/11 04:27:26 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1288.7 MiB so far)\n",
      "23/04/11 04:27:26 WARN BlockManager: Persisting block rdd_581_7 to disk instead.\n",
      "23/04/11 04:27:26 WARN MemoryStore: Not enough space to cache rdd_581_3 in memory! (computed 1288.7 MiB so far)\n",
      "23/04/11 04:27:26 WARN BlockManager: Persisting block rdd_581_3 to disk instead.\n",
      "23/04/11 04:27:27 WARN MemoryStore: Not enough space to cache rdd_581_4 in memory! (computed 1288.7 MiB so far)\n",
      "23/04/11 04:27:27 WARN BlockManager: Persisting block rdd_581_4 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 296:================>                                       (3 + 7) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:27:48 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 831.2 MiB so far)\n",
      "23/04/11 04:27:49 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 831.2 MiB so far)\n",
      "23/04/11 04:27:49 WARN BlockManager: Persisting block rdd_581_8 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 296:============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:28:08 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 1933.1 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 298:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:28:32 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1933.1 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 298:===========>                                            (2 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:28:40 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 20.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 300:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:29:10 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1933.1 MiB so far)\n",
      "23/04/11 04:29:17 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 20.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 302:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:29:47 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1933.1 MiB so far)\n",
      "23/04/11 04:29:55 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 20.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 304:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:30:26 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1933.1 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 304:=====>                                                  (1 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:30:36 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 20.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 306:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:31:08 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1933.1 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 306:=====>                                                  (1 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:31:19 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 20.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:31:44 WARN DAGScheduler: Broadcasting large task binary with size 1414.9 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 308:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:31:53 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1933.1 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 308:=================================>                      (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:32:06 WARN MemoryStore: Not enough space to cache rdd_581_9 in memory! (computed 161.0 MiB so far)\n",
      "23/04/11 04:32:06 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 161.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:32:33 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 310:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:32:42 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1933.1 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 310:=================================>                      (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:33:01 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 831.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:33:29 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 312:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:33:34 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 1288.7 MiB so far)\n",
      "23/04/11 04:33:34 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1288.7 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 312:============================>                           (5 + 5) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:33:57 WARN MemoryStore: Not enough space to cache rdd_581_8 in memory! (computed 549.9 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:34:28 WARN DAGScheduler: Broadcasting large task binary with size 8.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 314:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:34:33 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 1288.7 MiB so far)\n",
      "23/04/11 04:34:33 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 1288.7 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:35:34 WARN DAGScheduler: Broadcasting large task binary with size 14.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 316:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:35:36 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:35:36 WARN MemoryStore: Not enough space to cache rdd_581_4 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:35:38 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 831.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 316:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:36:38 WARN DAGScheduler: Broadcasting large task binary with size 1276.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:36:44 WARN DAGScheduler: Broadcasting large task binary with size 23.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 318:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:36:47 WARN MemoryStore: Not enough space to cache rdd_581_4 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:36:47 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:36:48 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 831.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 318:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:37:55 WARN DAGScheduler: Broadcasting large task binary with size 2038.9 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:38:04 WARN DAGScheduler: Broadcasting large task binary with size 34.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 320:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:38:07 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:38:07 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:38:09 WARN MemoryStore: Not enough space to cache rdd_581_4 in memory! (computed 831.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 320:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:39:18 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:39:31 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 322:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:39:34 WARN MemoryStore: Not enough space to cache rdd_581_4 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:39:34 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:39:36 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 831.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 322:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:40:23 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:40:35 WARN DAGScheduler: Broadcasting large task binary with size 37.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 324:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:40:39 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:40:39 WARN MemoryStore: Not enough space to cache rdd_581_4 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:40:40 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 831.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 324:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:41:19 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:41:32 WARN DAGScheduler: Broadcasting large task binary with size 36.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 326:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:41:36 WARN MemoryStore: Not enough space to cache rdd_581_4 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:41:36 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:41:37 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 831.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 326:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:42:24 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:42:36 WARN DAGScheduler: Broadcasting large task binary with size 29.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 328:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:42:39 WARN MemoryStore: Not enough space to cache rdd_581_4 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:42:39 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:42:40 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 831.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 328:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:43:07 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:43:16 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 330:>                                                       (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:43:19 WARN MemoryStore: Not enough space to cache rdd_581_7 in memory! (computed 549.9 MiB so far)\n",
      "23/04/11 04:43:19 WARN MemoryStore: Not enough space to cache rdd_581_5 in memory! (computed 549.9 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 336:==================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 15\n",
      "RMSE: 0.27059794177561736\n",
      "r2: 0.6136839625845653\n",
      "MAE: 0.22136124565755794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "#processed_train_df = spark.read.parquet(\"s3a://w210-bucket/data_wrangling/processed_df_train_redacted.parquet\")\n",
    "processed_train_df = spark.read.parquet(\"s3a://w210-bucket/data_wrangling/murray_processed_df_train_redacted.parquet\")\n",
    "#processed_test_df = spark.read.parquet(\"s3a://w210-bucket/data_wrangling/processed_df_test_redacted.parquet\")\n",
    "processed_test_df = spark.read.parquet(\"s3a://w210-bucket/data_wrangling/murray_processed_df_test_redacted.parquet\")\n",
    "processed_train_df = processed_train_df.withColumn(\"log_ridership_number\",log10(col('ridership_number'))).drop(\"ridership_number\")\n",
    "processed_test_df  = processed_test_df.withColumn(\"log_ridership_number\",log10(col('ridership_number'))).drop(\"ridership_number\")\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "max_Depth = [15]\n",
    "\n",
    "for d in max_Depth:\n",
    "    rf = RandomForestRegressor(featuresCol = 'features', labelCol = 'log_ridership_number', maxDepth = d)\n",
    "    rf_model = rf.fit(processed_train_df)\n",
    "    rf_model.getNumTrees\n",
    "    rf_predictions = rf_model.transform(processed_test_df)\n",
    "\n",
    "    rf_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"log_ridership_number\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse_rf = rf_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "    rf_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"log_ridership_number\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "    r2_rf = rf_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "    rf_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"log_ridership_number\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "    mae_rf = rf_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "    print(f'Max Depth: {d}')\n",
    "    print(f\"RMSE: {rmse_rf}\")\n",
    "    print(f\"r2: {r2_rf}\")\n",
    "    print(f\"MAE: {mae_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fc829a6-82ed-41fc-b1d0-66f807f0747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 04:50:43 WARN TaskSetManager: Stage 342 contains a task of very large size (3430 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf_model.save(\"s3a://w210-bucket/additional_models/murray_rf_model_basic_data.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ece25e-94ce-429a-a2d5-76e7c14a5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the random saved model from S3 Bucket\n",
    "# rf_model = RandomForestRegressionModel.load(\"s3a://w210-bucket/models/rf_model_max_depth_20.model\")\n",
    "# print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee2e97b2-6bc5-4488-a4a8-80568d2ba49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mapping Features names to the model\n",
    "# attrs = sorted((attr[\"idx\"], attr[\"name\"])\n",
    "#     for attr in (chain(*processed_train_df.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"].values()))\n",
    "# ) \n",
    "\n",
    "# feature_importance_mapped = [(name, rf_model.featureImportances[idx])\n",
    "#     for idx, name in attrs\n",
    "#     if rf_model.featureImportances[idx]\n",
    "# ]\n",
    "# sorted(feature_importance_mapped, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1734a-5a95-4314-8c93-6498ad9fc353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98bc2186-bd58-42c2-9f4b-2f8b938c66e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling with no weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8481c2f7-b04b-453a-bb19-21f24e850578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:09:17 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"s3a://w210-bucket/data_wrangling/final_df_prior_hr.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77bcb41a-f6b1-4836-a7bf-1ea6964bf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redacted = df.drop('wind_speed_origin','air_temp_origin','precipitation_origin','wth_type_origin',\n",
    "                      'wind_speed_dest','air_temp_dest','precipitation_dest','precipitation_dest','wth_type_dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4cb5e8-d8d7-4b60-8cc1-575ea7ab51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# casting certain columns to integer\n",
    "df_redacted = df_redacted.withColumn('day_of_month', dayofmonth(df_redacted.date)) \\\n",
    "       .withColumn('day_of_year', dayofyear(df_redacted.date)) \n",
    "df_redacted= df_redacted.withColumn(\"year\",col(\"year\").cast('integer'))  \n",
    "\n",
    "df_redacted = df_redacted.withColumn('average_route_crowd',f.when(f.col(\"average_route_crowd\").isNull(),f.lit(0)).otherwise(df_redacted.average_route_crowd))\n",
    "df_redacted = df_redacted.withColumn('prior_hr_route_crowd',f.when(f.col(\"prior_hr_route_crowd\").isNull(),f.lit(0)).otherwise(df_redacted.prior_hr_route_crowd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb058eb-f66b-4cab-a315-d977478d50c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "columns_categorical = ['hour','day_of_week','month','day_of_month','quarter','day_of_year','origin','destination',\n",
    "                      'event_origin','event_dest','holiday_period']\n",
    "\n",
    "\n",
    "columns_continues = ['year','average_route_crowd','prior_hr_route_crowd','number_of_searches']\n",
    "\n",
    "##### indexing and one hot encoding categorical features\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"hour\", outputCol=\"hour_index\")\n",
    "df_final = indexer.fit(df_redacted).transform(df_redacted)\n",
    "ohe = OneHotEncoder(inputCol=\"hour_index\", outputCol=\"hour_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"day_of_week\", outputCol=\"day_of_week_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"day_of_week_index\", outputCol=\"day_of_week_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"month\", outputCol=\"month_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"month_index\", outputCol=\"month_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"day_of_month\", outputCol=\"day_of_month_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"day_of_month_index\", outputCol=\"day_of_month_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"quarter\", outputCol=\"quarter_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"quarter_index\", outputCol=\"quarter_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"day_of_year\", outputCol=\"day_of_year_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"day_of_year_index\", outputCol=\"day_of_year_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"origin\", outputCol=\"origin_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"origin_index\", outputCol=\"origin_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"destination\", outputCol=\"destination_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"destination_index\", outputCol=\"destination_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"event_origin\", outputCol=\"event_origin_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"event_origin_index\", outputCol=\"event_origin_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"event_dest\", outputCol=\"event_dest_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"event_dest_index\", outputCol=\"event_dest_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"holiday_period\", outputCol=\"holiday_period_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "ohe = OneHotEncoder(inputCol=\"holiday_period_index\", outputCol=\"holiday_period_index_ohe\")\n",
    "df_final = ohe.fit(df_final).transform(df_final)\n",
    "\n",
    "\n",
    "# Vectore assembling categorical features\n",
    "assembler_categ = VectorAssembler(inputCols= ['hour_index_ohe','day_of_week_index_ohe','month_index_ohe',\n",
    "                                              'day_of_month_index_ohe','quarter_index_ohe','day_of_year_index_ohe',\n",
    "                                              'origin_index_ohe','destination_index_ohe','event_origin_index_ohe',\n",
    "                                              'event_dest_index_ohe',\n",
    "                                              'holiday_period_index_ohe'],\n",
    "                           outputCol=\"cat_features\")\n",
    "\n",
    "\n",
    "# Vector assembling continues features\n",
    "assembler_cont = VectorAssembler(inputCols=columns_continues,\n",
    "                                   outputCol=\"cont_features\")\n",
    "\n",
    "# transforming the data\n",
    "df_final = assembler_categ.transform(df_final)\n",
    "df_final = assembler_cont.transform(df_final)\n",
    "assembler = VectorAssembler(inputCols= [\"cont_features\",\"cat_features\"],\n",
    "                               outputCol=\"features\")\n",
    "\n",
    "df_final = assembler.transform(df_final)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4feceaf-2cf2-4a18-be29-158912e4fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_1 = df_final.filter(col('year') != 2011)\n",
    "processed_train_df = df_final_1.filter(col('year') != 2022).select('ridership_number','features')\n",
    "processed_test_df =  df_final_1.filter(col('year') == 2022).select('ridership_number','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d08b28f-f66a-4621-bda5-c90dda04d18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# saving as parquet in S3 bucket\n",
    "# processed_train_df.write.parquet('s3a://w210-bucket/data_wrangling/processed_df_train_no_weather.parquet',mode='overwrite')\n",
    "# processed_test_df.write.parquet('s3a://w210-bucket/data_wrangling/processed_df_test_no_weather.parquet',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b0e72-5b25-4348-be23-872a63ca4976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:29:14 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:29:14 WARN BlockManager: Persisting block rdd_119_3 to disk instead.\n",
      "23/04/10 22:29:14 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:29:14 WARN BlockManager: Persisting block rdd_119_4 to disk instead.\n",
      "23/04/10 22:29:14 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:29:14 WARN BlockManager: Persisting block rdd_119_7 to disk instead.\n",
      "23/04/10 22:29:15 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:29:15 WARN BlockManager: Persisting block rdd_119_5 to disk instead.\n",
      "23/04/10 22:29:15 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:29:15 WARN BlockManager: Persisting block rdd_119_0 to disk instead.\n",
      "23/04/10 22:29:15 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:29:15 WARN BlockManager: Persisting block rdd_119_2 to disk instead.\n",
      "23/04/10 22:29:45 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 4.3 GiB so far)\n",
      "23/04/10 22:29:45 WARN BlockManager: Persisting block rdd_119_6 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:30:34 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 10.1 GiB so far)\n",
      "23/04/10 22:30:34 WARN BlockManager: Persisting block rdd_119_1 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:33:10 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 22:33:11 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 22:33:13 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 553.7 MiB so far)\n",
      "23/04/10 22:33:14 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 22:33:14 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 836.8 MiB so far)\n",
      "23/04/10 22:33:15 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 20.2 MiB so far)\n",
      "23/04/10 22:33:16 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 22:33:29 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:=======================>                                 (5 + 7) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:37:48 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:37:48 WARN BlockManager: Persisting block rdd_119_11 to disk instead.\n",
      "23/04/10 22:37:50 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 22:37:50 WARN BlockManager: Persisting block rdd_119_10 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:============================>                            (6 + 6) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:37:57 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n",
      "23/04/10 22:37:57 WARN BlockManager: Persisting block rdd_119_8 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:38:31 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 10.1 GiB so far)\n",
      "23/04/10 22:38:31 WARN BlockManager: Persisting block rdd_119_9 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:40:05 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 22:40:06 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 6.4 GiB so far)\n",
      "23/04/10 22:40:07 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 22:40:43 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 4.3 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:43:16 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:43:16 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:43:16 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:43:16 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:43:16 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:43:16 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:43:19 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 22:43:20 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:=======================>                                 (5 + 7) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:47:56 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 22:47:58 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:47:59 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:============================>                            (6 + 6) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:48:02 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:50:54 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:50:54 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:50:54 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:50:54 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:50:54 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:50:54 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:50:57 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 22:50:57 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:55:43 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 366.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:=======================>                                 (5 + 7) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:55:45 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n",
      "23/04/10 22:55:47 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:============================>                            (6 + 6) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:55:48 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 4.3 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 22:58:40 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:58:40 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:58:40 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:58:41 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:58:41 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:58:41 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 22:58:44 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 22:58:44 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:=======================>                                 (5 + 7) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:03:48 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:=================================>                       (7 + 5) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:03:52 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 23:03:53 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:03:54 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:06:50 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:06:50 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:06:50 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:06:50 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:06:50 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:06:50 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:06:53 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 23:06:54 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:12:10 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 23:12:11 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:12:12 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n",
      "23/04/10 23:12:12 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:15:33 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:15:33 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:15:34 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:15:34 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:15:34 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:15:34 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:15:37 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 23:15:37 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:21:05 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n",
      "23/04/10 23:21:06 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 23:21:08 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:21:09 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:24:41 WARN DAGScheduler: Broadcasting large task binary with size 1433.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:24:48 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:24:48 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:24:48 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:24:48 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:24:48 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:24:48 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:24:52 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 23:24:52 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:30:50 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n",
      "23/04/10 23:30:51 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:30:52 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 23:30:53 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:34:47 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:34:54 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:34:54 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:34:54 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:34:54 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:34:55 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:34:55 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:34:57 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 23:34:58 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:41:43 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:41:44 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:41:45 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:=======================>                                 (5 + 7) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:41:52 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 6.4 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:46:02 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:46:09 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:46:09 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:46:09 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:46:09 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:46:09 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:46:09 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:46:13 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 23:46:13 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:53:25 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n",
      "23/04/10 23:53:29 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n",
      "23/04/10 23:53:30 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:53:31 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:58:14 WARN DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 23:58:22 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:58:22 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:58:22 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:58:22 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:58:22 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:58:22 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/10 23:58:26 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/10 23:58:26 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:06:31 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:06:32 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n",
      "23/04/11 00:06:33 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:06:40 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 6.4 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:12:01 WARN DAGScheduler: Broadcasting large task binary with size 18.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:12:08 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:12:08 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:12:09 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:12:09 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:12:09 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:12:09 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:12:12 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/11 00:12:12 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:21:18 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n",
      "23/04/11 00:21:18 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 553.7 MiB so far)\n",
      "23/04/11 00:21:19 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/11 00:21:25 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 6.4 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:27:22 WARN DAGScheduler: Broadcasting large task binary with size 1704.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:27:31 WARN DAGScheduler: Broadcasting large task binary with size 30.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:27:39 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:27:39 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:27:39 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:27:39 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:27:39 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:27:39 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:27:43 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/11 00:27:43 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:==============>                                          (3 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:36:30 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:36:33 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n",
      "23/04/11 00:36:34 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 366.6 MiB so far)\n",
      "23/04/11 00:36:40 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 4.3 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:42:32 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:42:44 WARN DAGScheduler: Broadcasting large task binary with size 30.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:42:51 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:42:52 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:42:52 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:42:52 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:42:52 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:42:53 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:42:55 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/11 00:42:56 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:48:24 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n",
      "23/04/11 00:48:24 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n",
      "23/04/11 00:48:24 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1297.5 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:=======================>                                 (5 + 7) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:48:26 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:52:08 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:52:20 WARN DAGScheduler: Broadcasting large task binary with size 32.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:52:27 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:52:27 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:52:28 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:52:28 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:52:28 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:52:29 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:52:31 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/11 00:52:32 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:=======================>                                 (5 + 7) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:56:19 WARN MemoryStore: Not enough space to cache rdd_119_9 in memory! (computed 2.9 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:============================>                            (6 + 6) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:56:20 WARN MemoryStore: Not enough space to cache rdd_119_10 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:=================================>                       (7 + 5) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:56:21 WARN MemoryStore: Not enough space to cache rdd_119_11 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/11 00:56:22 WARN MemoryStore: Not enough space to cache rdd_119_8 in memory! (computed 4.3 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:58:50 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:>                                                        (0 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:59:01 WARN DAGScheduler: Broadcasting large task binary with size 35.0 MiB\n",
      "23/04/11 00:59:09 WARN MemoryStore: Not enough space to cache rdd_119_2 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:59:09 WARN MemoryStore: Not enough space to cache rdd_119_0 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:59:09 WARN MemoryStore: Not enough space to cache rdd_119_3 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:59:10 WARN MemoryStore: Not enough space to cache rdd_119_7 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:59:10 WARN MemoryStore: Not enough space to cache rdd_119_6 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:59:11 WARN MemoryStore: Not enough space to cache rdd_119_1 in memory! (computed 1297.5 MiB so far)\n",
      "23/04/11 00:59:13 WARN MemoryStore: Not enough space to cache rdd_119_5 in memory! (computed 1946.3 MiB so far)\n",
      "23/04/11 00:59:14 WARN MemoryStore: Not enough space to cache rdd_119_4 in memory! (computed 1946.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:>                                                        (0 + 8) / 12]\r"
     ]
    }
   ],
   "source": [
    "# Reading Data\n",
    "# taking log10 of the outcome variable \n",
    "processed_train_df = spark.read.parquet(\"s3a://w210-bucket/data_wrangling/processed_df_train_no_weather.parquet\")\n",
    "processed_test_df = spark.read.parquet(\"s3a://w210-bucket/data_wrangling/processed_df_test_no_weather.parquet\")\n",
    "processed_train_df = processed_train_df.withColumn(\"log_ridership_number\",log10(col('ridership_number'))).drop(\"ridership_number\")\n",
    "processed_test_df  = processed_test_df.withColumn(\"log_ridership_number\",log10(col('ridership_number'))).drop(\"ridership_number\")\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "max_Depth = [15]\n",
    "\n",
    "for d in max_Depth:\n",
    "    rf = RandomForestRegressor(featuresCol = 'features', labelCol = 'log_ridership_number', maxDepth = d)\n",
    "    rf_model = rf.fit(processed_train_df)\n",
    "    rf_model.getNumTrees\n",
    "    rf_predictions = rf_model.transform(processed_test_df)\n",
    "\n",
    "    rf_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"log_ridership_number\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse_rf = rf_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "    rf_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"log_ridership_number\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "    r2_rf = rf_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "    rf_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"log_ridership_number\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "    mae_rf = rf_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "    print(f'Max Depth: {d}')\n",
    "    print(f\"RMSE: {rmse_rf}\")\n",
    "    print(f\"r2: {r2_rf}\")\n",
    "    print(f\"MAE: {mae_rf}\")\n",
    "    \n",
    "    rf_model.save(\"s3a://w210-bucket/additional_models/rf_model_no_weather.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f73143-7cfb-456c-b1dc-e1d6c587b958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
